{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPE05UcJru1S6NOQA0xACN+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"krdDJmDFw0c0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718883437317,"user_tz":-60,"elapsed":27050,"user":{"displayName":"Isabel Ronan","userId":"07917616884202561923"}},"outputId":"4c9eb5af-6d2b-4626-e9dd-c890bacbd260"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m974.6/974.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m321.8/321.8 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.1/127.1 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m326.8/326.8 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.0/145.0 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["# imports needed for google colab\n","!pip install -q langchain langchain_core langchain_openai"]},{"cell_type":"code","source":["# import libraries\n","from langchain_core.prompts import PromptTemplate\n","from langchain.chains import SequentialChain, LLMChain\n","from langchain_openai import ChatOpenAI\n","\n","import pandas as pd\n","import os\n","import re\n","\n","from google.colab import drive\n","from google.colab import userdata"],"metadata":{"id":"yCmnQuJixWNa","executionInfo":{"status":"ok","timestamp":1718883440903,"user_tz":-60,"elapsed":3592,"user":{"displayName":"Isabel Ronan","userId":"07917616884202561923"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# mount the drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B2z8eZ1nyMyE","executionInfo":{"status":"ok","timestamp":1718883480892,"user_tz":-60,"elapsed":16147,"user":{"displayName":"Isabel Ronan","userId":"07917616884202561923"}},"outputId":"353da0b9-4aa5-4a32-c628-6bbfef523a19"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# get openai api key\n","openai_api_key = userdata.get('open_ai_project_nurse_notes')"],"metadata":{"id":"AQtRhWBDIFpi","executionInfo":{"status":"ok","timestamp":1718883487325,"user_tz":-60,"elapsed":4006,"user":{"displayName":"Isabel Ronan","userId":"07917616884202561923"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["def generate_notes(system_role_prompt, note_query_prompt, input_data, openai_api_key, temperature, model, completions, filename):\n","  # generate and save notes\n","\n","  def parse_and_clean_reports(results):\n","    # parse and clean reports from openai completions\n","    reports = []\n","    for result in results:\n","        splits = result['output'].split('***')\n","        for split in splits:\n","          more_split = split.split('\"')\n","          for another_split in more_split:\n","            another_split = another_split.replace('\\n', '')\n","            if not \":\" in another_split:\n","              if not '\"' in another_split:\n","                if re.search('[a-zA-Z]', another_split):\n","                  reports.append(another_split)\n","    return reports\n","\n","  def save_reports(reports, needs, filename):\n","    # save the responses to a CSV file\n","    df = pd.DataFrame(reports, columns=['report'])\n","    df['needs'] = needs\n","    try:\n","        df.to_csv(filename, index=False)\n","        print(f\"Reports saved successfully to {filename}\")\n","    except Exception as e:\n","        print(f\"Failed to save reports: {str(e)}\")\n","\n","  data_dir = '/content/drive/MyDrive/Colab Notebooks/GenCareAI/GenCareAI/data/gpt4'\n","  report_filepath = os.path.join(data_dir, f'{filename}_{input_data[\"needs\"]}.csv')\n","\n","  # initialize openai model\n","  llm = ChatOpenAI(api_key=openai_api_key, temperature=temperature, model=model)\n","\n","  # create prompts\n","  role_prompt = PromptTemplate(template=system_role_prompt['message'], input_variables=system_role_prompt['inputs'])\n","  note_prompt = PromptTemplate(template=note_query_prompt['message'], input_variables=note_query_prompt['inputs'])\n","\n","  # create llmchains\n","  role_chain = LLMChain(llm=llm, prompt=role_prompt, output_key = \"intermediate_output\")\n","  note_chain = LLMChain(llm=llm, prompt=note_prompt, output_key = \"output\")\n","  # create sequentialchain\n","  sequential_chain = SequentialChain(\n","      chains=[role_chain, note_chain], input_variables = (system_role_prompt['inputs'] + note_query_prompt['inputs']), output_variables = [\"output\"]\n","  )\n","\n","  # generate a number of different responses\n","  results = []\n","  for _ in range(completions):\n","    response = sequential_chain.invoke(input_data)\n","    results.append(response)\n","\n","  # clean results\n","  results = parse_and_clean_reports(results)\n","  # save results\n","  save_reports(results, input_data[\"needs\"], report_filepath)\n"],"metadata":{"id":"4TE6H3jR0TrI","executionInfo":{"status":"ok","timestamp":1718883488571,"user_tz":-60,"elapsed":235,"user":{"displayName":"Isabel Ronan","userId":"07917616884202561923"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["system_role_prompt = {'message':\n","                      '''\n","                      You are a specialist in generating fictitious data for natural language processing projects in healthcare.\n","                      You speak the language of a nurse in an {nationality} nursing home. Namely, you speak {language}.\n","                      ''' ,\n","                      'inputs':[\"nationality\", \"language\"]}\n","\n","note_query_prompt = {'message':\n","                      '''\n","                      This is an example of a nurse note for a patient in a day: \"{example_note}\"\n","\n","                      Other reports may include: washing, dressing, brushing teeth, getting ready for the day, getting ready for the night, showering, cleaning dental prostheses, or assistance after incontinence.\n","                      Other reports could include: what the client has or has not eaten, what help is needed with eating (full help, encouragement, adapted cutlery or cup), choking, keeping hydration and nutrition lists.\n","                      Other reports could include: Organised activities, getting visitors, browsing through a magazine, interacting with fellow residents. Keep in mind that these are reports from people in a nursing home, with severe disabilities, so social interaction and activities are limited. Usually it involves sociability, but not always.\n","                      Other reports may include, for example: oedema, pressure ulcers, peeling, redness and itching of the skin. Nails that are too long, blemishes.\n","                      Other reports could include, for example: care plan discussions, minor medical complaints, family requests, ordering medication.\n","                      Reports can be, for example, about: restlessness and wandering at night, sleeping well, going to the toilet at night, phoning, lying crookedly in bed.\n","                      Reports may include: agitation, restlessness, apathy, confusion; usually the confusion is subtle, but sometimes more intense.\n","                      Reports may include, for example: pain, tightness of breath, nausea, diarrhoea, back pain, palliative care; usually the complaints are subtle, but sometimes more severe.\n","                      Other reports can be about, for example: walking aids, the wheelchair, falls, fall incidents, transfers, lifts.\n","                      Most reports are about everyday things, so not everything is a serious incident.\n","\n","                      Make up {number_of_reports} such reports for {number_of_reports} residents with {needs} palliative care needs. Return only the reports, with each report separated by \"***\" and nothing else. Vary the sentence structure and style.\n","                      ''' ,\n","                      'inputs':[\"example_note\", \"number_of_reports\", \"needs\"]}"],"metadata":{"id":"zWgiOyYUGtpv","executionInfo":{"status":"ok","timestamp":1718883492294,"user_tz":-60,"elapsed":263,"user":{"displayName":"Isabel Ronan","userId":"07917616884202561923"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["DATA_LOADING_DIR = '/content/drive/MyDrive/Colab Notebooks/GenCareAI/GenCareAI'\n","dataframe = pd.read_excel(f'{DATA_LOADING_DIR}/fake_notes.xlsx')\n","completions = 25\n","model = 'gpt-4o-2024-05-13'\n","temperature = 1.1\n","\n","for index, row in dataframe.iterrows():\n","  input_data = {'nationality': 'Irish', 'language': 'Hiberno-English', 'example_note': row.Note, 'number_of_reports': 25, 'needs': row.Needs}\n","  generate_notes(system_role_prompt, note_query_prompt, input_data, openai_api_key, temperature, model, completions, index % 5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QeNhMAzI7fw9","executionInfo":{"status":"ok","timestamp":1718890118269,"user_tz":-60,"elapsed":2465150,"user":{"displayName":"Isabel Ronan","userId":"07917616884202561923"}},"outputId":"0c0120f1-abf6-40e9-bde5-3b823683600c"},"execution_count":7,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 0.3.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n","  warn_deprecated(\n"]},{"output_type":"stream","name":"stdout","text":["Reports saved successfully to /content/drive/MyDrive/Colab Notebooks/GenCareAI/GenCareAI/data/gpt4/0_met.csv\n","Reports saved successfully to /content/drive/MyDrive/Colab Notebooks/GenCareAI/GenCareAI/data/gpt4/1_met.csv\n","Reports saved successfully to /content/drive/MyDrive/Colab Notebooks/GenCareAI/GenCareAI/data/gpt4/2_met.csv\n","Reports saved successfully to /content/drive/MyDrive/Colab Notebooks/GenCareAI/GenCareAI/data/gpt4/3_met.csv\n","Reports saved successfully to /content/drive/MyDrive/Colab Notebooks/GenCareAI/GenCareAI/data/gpt4/4_met.csv\n","Reports saved successfully to /content/drive/MyDrive/Colab Notebooks/GenCareAI/GenCareAI/data/gpt4/0_unmet.csv\n","Reports saved successfully to /content/drive/MyDrive/Colab Notebooks/GenCareAI/GenCareAI/data/gpt4/1_unmet.csv\n","Reports saved successfully to /content/drive/MyDrive/Colab Notebooks/GenCareAI/GenCareAI/data/gpt4/2_unmet.csv\n","Reports saved successfully to /content/drive/MyDrive/Colab Notebooks/GenCareAI/GenCareAI/data/gpt4/3_unmet.csv\n","Reports saved successfully to /content/drive/MyDrive/Colab Notebooks/GenCareAI/GenCareAI/data/gpt4/4_unmet.csv\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"nbDP4kXacKQn"},"execution_count":null,"outputs":[]}]}